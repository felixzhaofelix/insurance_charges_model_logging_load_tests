{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Installer le modèle du projet personnel: logging-of-regression-model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb8cda903d7c2a3a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268ca81a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T20:58:23.966521Z",
     "start_time": "2023-12-14T20:57:41.618627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining insurance_charges_model from git+https://github.com/uqam-lomagnin/logging-of-regression-model-felixzhaofelix.git@main#egg=insurance_charges_model\r\n",
      "\u001B[33m  WARNING: git clone in /Users/felixzhao/venv/src/insurance-charges-model exists with URL https://github.com/felixzhaofelix/regression-model-fixed/\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  WARNING: The plan is to install the git repository https://github.com/uqam-lomagnin/logging-of-regression-model-felixzhaofelix.git\u001B[0m\u001B[33m\r\n",
      "\u001B[0mWhat to do?  (s)witch, (i)gnore, (w)ipe, (b)ackup ^C\r\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "!pip install -e git+https://github.com/uqam-lomagnin/logging-of-regression-model-felixzhaofelix.git@main#egg=insurance_charges_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8473fbe",
   "metadata": {},
   "source": [
    "Importons le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764faa98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T20:58:29.937901Z",
     "start_time": "2023-12-14T20:58:29.907776Z"
    }
   },
   "outputs": [],
   "source": [
    "from insurance_charges_model.prediction.model import InsuranceChargesModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f0dd4f",
   "metadata": {},
   "source": [
    "Instancions le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc73406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceChargesModel()\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Faisons un exemple de prédiction avec l'objet InsuranceChargesModelInput :"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24455ae6d1f72c21"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016156e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T20:58:36.243144Z",
     "start_time": "2023-12-14T20:58:36.212682Z"
    }
   },
   "outputs": [],
   "source": [
    "from insurance_charges_model.prediction.schemas import InsuranceChargesModelInput, \\\n",
    "    SexEnum, RegionEnum\n",
    "\n",
    "model_input = InsuranceChargesModelInput(\n",
    "    age=42, \n",
    "    sex=SexEnum.female,\n",
    "    bmi=24.0,\n",
    "    children=2,\n",
    "    smoker=False,\n",
    "    region=RegionEnum.northwest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb608e8",
   "metadata": {},
   "source": [
    "Avec cet objet, nous pouvons faire une prédiction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ec2c2ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T20:58:38.895020Z",
     "start_time": "2023-12-14T20:58:38.853831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "InsuranceChargesModelOutput(charges=8219.96)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(model_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d112c",
   "metadata": {},
   "source": [
    "Le modèle prédit que les frais seront de 8219,96 $. Résultat du nouveau modèle 2023 réentraîné par Groupe 1\n",
    "\n",
    "Et on peut voir le schéma d'entrée du modèle en invoquant la méthode schema() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d2d443b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T20:58:43.652967Z",
     "start_time": "2023-12-14T20:58:43.614173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'title': 'InsuranceChargesModelInput',\n 'description': \"Schema for input of the model's predict method.\",\n 'type': 'object',\n 'properties': {'age': {'title': 'Age',\n   'description': 'Age of primary beneficiary in years.',\n   'minimum': 18,\n   'maximum': 65,\n   'type': 'integer'},\n  'sex': {'title': 'Sex',\n   'description': 'Gender of beneficiary.',\n   'allOf': [{'$ref': '#/definitions/SexEnum'}]},\n  'bmi': {'title': 'Body Mass Index',\n   'description': 'Body mass index of beneficiary.',\n   'minimum': 15.0,\n   'maximum': 50.0,\n   'type': 'number'},\n  'children': {'title': 'Children',\n   'description': 'Number of children covered by health insurance.',\n   'minimum': 0,\n   'maximum': 5,\n   'type': 'integer'},\n  'smoker': {'title': 'Smoker',\n   'description': 'Whether beneficiary is a smoker.',\n   'type': 'boolean'},\n  'region': {'title': 'Region',\n   'description': 'Region where beneficiary lives.',\n   'allOf': [{'$ref': '#/definitions/RegionEnum'}]}},\n 'definitions': {'SexEnum': {'title': 'SexEnum',\n   'description': \"Enumeration for the value of the 'sex' input of the model.\",\n   'enum': ['male', 'female'],\n   'type': 'string'},\n  'RegionEnum': {'title': 'RegionEnum',\n   'description': \"Enumeration for the value of the 'region' input of the model.\",\n   'enum': ['southwest', 'southeast', 'northwest', 'northeast'],\n   'type': 'string'}}}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7628bd2476643b8b"
  },
  {
   "cell_type": "markdown",
   "id": "e25b0005",
   "metadata": {},
   "source": [
    "Et on aura besoin de ce schéma pour faire des fausses prédictions pour charger le modèle pour conduire le test de charge : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc9cd7",
   "metadata": {},
   "source": [
    "## Profilage du Modèle\n",
    "\n",
    "Afin d'avoir une idée du temps nécessaire à notre modèle pour effectuer une prédiction, nous allons le profiler en réalisant des prédictions avec des données aléatoires. Pour ce faire, nous utiliserons le package Faker : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9637eb25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T20:58:27.482803Z",
     "start_time": "2023-12-14T20:58:25.888133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Faker in /Users/felixzhao/venv/lib/python3.9/site-packages (21.0.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /Users/felixzhao/venv/lib/python3.9/site-packages (from Faker) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/felixzhao/venv/lib/python3.9/site-packages (from python-dateutil>=2.4->Faker) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install Faker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Créons une nouvelle fonction generate_record() qui va générer un enregistrement aléatoire qui respecte le schéma d'entrée du modèle :\n",
    "\n",
    "faker génère des données aléatoires pour simuler les vraies requêtes des clients, et nous retourne un objet de type InsuranceChargesModelInput pour aliment le modèle."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dabc38429a8ae49"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96c522db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T20:59:22.410096Z",
     "start_time": "2023-12-14T20:59:22.343767Z"
    }
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "def generate_record() -> InsuranceChargesModelInput:\n",
    "    record = {\n",
    "        \"age\": faker.random_int(min=18, max=65),\n",
    "        \"sex\": faker.random_choices(elements=(\"male\", \"female\"), length=1)[0],\n",
    "        \"bmi\": faker.random_int(min=15000, max=50000)/1000.0,\n",
    "        \"children\": faker.random_int(min=0, max=5),\n",
    "        \"smoker\": faker.boolean(),\n",
    "        \"region\": faker.random_choices(elements=(\"southwest\", \"southeast\", \"northwest\", \"northeast\"), length=1)[0]\n",
    "    }\n",
    "    return InsuranceChargesModelInput(**record)\n",
    "\n",
    "myInput = generate_record()   "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voici le résultat de l'exécution de la fonction :\n",
    "InsuranceChargesModelInput(\n",
    "age=32, \n",
    "sex=<SexEnum.male: 'male'>, \n",
    "bmi=15.444, \n",
    "children=4, \n",
    "smoker=True, \n",
    "region=<RegionEnum.northeast: 'northeast'>)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31304c8e4889090d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "InsuranceChargesModelOutput(charges=39330.45)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myPrediction = model.predict(myInput)\n",
    "\n",
    "myPrediction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T21:00:06.363127Z",
     "start_time": "2023-12-14T21:00:06.324955Z"
    }
   },
   "id": "6ed67de4db5d4cb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Maintenant nous savons que ça marche, donc nous allons en faire mille copies aléatoires et les stocker dans une liste :"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "535e31aa65337c2b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3605a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:48:46.512535Z",
     "start_time": "2023-12-14T01:48:46.462748Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    samples.append(generate_record())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c3a43",
   "metadata": {},
   "source": [
    "Avec le module timeit de la bibliothèque standard, nous pouvons mesurer le temps nécessaire pour appeler la méthode de prédiction du modèle avec un échantillon aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d48772f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:49:24.210894Z",
     "start_time": "2023-12-14T01:49:15.167742Z"
    }
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "total_seconds = timeit.timeit(\"[model.predict(sample) for sample in samples]\", \n",
    "                              number=1, globals=globals())\n",
    "\n",
    "seconds_per_sample = total_seconds / len(samples)\n",
    "milliseconds_per_sample = seconds_per_sample * 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6db0b50f",
   "metadata": {
    "tags": [
     "hide_code"
    ],
    "ExecuteTime": {
     "end_time": "2023-12-14T01:50:58.103292Z",
     "start_time": "2023-12-14T01:50:58.074235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "Le modèle a pris 9.01 secondes pour exécuter 1000 prédictions, donc il a pris 0.009 secondes pour faire une seule prédiction. Le modèle prend 9.01 millisecondes pour faire une prédiction."
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(\"Le modèle a pris {} secondes pour exécuter 1000 prédictions, donc il a pris {} secondes \"\n",
    "   \"pour faire une seule prédiction. Le modèle prend {} millisecondes pour faire une prédiction.\"\n",
    "   .format(round(total_seconds, 2),\n",
    "           round(seconds_per_sample, 3),\n",
    "           round(milliseconds_per_sample,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1440dc",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant établir un SLO (Service Level Objective) pour le modèle. Disons que c'est acceptable que le modèle fasse une prédiction en moins de 100 ms. Nous pouvons formaliser cette exigence comme ceci avec assert :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aea0ff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:51:29.476513Z",
     "start_time": "2023-12-14T01:51:29.444485Z"
    }
   },
   "outputs": [],
   "source": [
    "assert milliseconds_per_sample < 100, \"Model does not meet the latency SLO.\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rien n'est imprimé, donc notre modèle est conforme au critère d'exigence.\n",
    "\n",
    "Passons à la prochaine étape pour tester le service avec plusieurs utilisateurs simultanés."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c81fd2ebdca1dfc"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "!pip install rest_model_service\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "782e6baf"
  },
  {
   "cell_type": "markdown",
   "id": "40497411",
   "metadata": {},
   "source": [
    "Faisons-le fonctionner :\n",
    "\n",
    "```bash\n",
    "export PYTHONPATH=./\n",
    "export REST_CONFIG=./configuration/rest_configuration.yaml\n",
    "uvicorn rest_model_service.main:app --reload\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d191a69",
   "metadata": {},
   "source": [
    "## Créer un service de test Locust\n",
    "\n",
    "Utilisons locust pour faire des requêtes au service de modèle. Locust est un outil de test de charge qui permet de simuler des utilisateurs simultanés qui font des requêtes à un service. Nous allons utiliser locust pour simuler des utilisateurs qui font des requêtes au service de modèle.\n",
    "\n",
    "```bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da5cec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install locust\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Incorporons la méthdoe de Faker dans la classe de HttpUser de Locust  pour simuler des utilisateurs qui font des requêtes au service de modèle.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60e50d97c2bc3584"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "```python\n",
    "from locust import HttpUser, constant_throughput, task\n",
    "from faker import Faker\n",
    "\n",
    "\n",
    "class ModelServiceUser(HttpUser):\n",
    "    wait_time = constant_throughput(1)\n",
    "\n",
    "    @task\n",
    "    def post_prediction(self):\n",
    "        faker = Faker()\n",
    "        \n",
    "        record = {\n",
    "            \"age\": faker.random_int(min=18, max=65),\n",
    "            \"sex\": faker.random_choices(elements=(\"male\", \"female\"), length=1)[0],\n",
    "            \"bmi\": faker.random_int(min=15000, max=50000) / 1000.0,\n",
    "            \"children\": faker.random_int(min=0, max=5),\n",
    "            \"smoker\": faker.boolean(),\n",
    "            \"region\": faker.random_choices(\n",
    "                elements=(\"southwest\", \"southeast\", \"northwest\", \"northeast\"), length=1)[0]\n",
    "        }\n",
    "        self.client.post(\"/api/models/insurance_charges_model/prediction\", json=record)\n",
    "```\n",
    "Pour refléter la réalité, ajoutons aussi progressivement des faux utilisateurs pour charger le service : \n",
    "À tous les intervalles de 30 secondes, nous allons ajouter 1 utilisateur supplémentaire jusqu'à ce que nous ayons 5 utilisateurs simultanés et revenir \n",
    "à 1 utilisateur à la fin du test avec le même rythme. Nous allons utiliser la classe LoadTestShape de locust pour définir cette forme de charge.\n",
    "\n",
    "```python\n",
    "from locust import LoadTestShape\n",
    "\n",
    "\n",
    "class StagesShape(LoadTestShape):\n",
    "    \"\"\"Simple load test shape class.\"\"\"\n",
    "\n",
    "    stages = [\n",
    "        {\"duration\": 30, \"users\": 1, \"spawn_rate\": 1},\n",
    "        {\"duration\": 60, \"users\": 2, \"spawn_rate\": 1},\n",
    "        {\"duration\": 90, \"users\": 3, \"spawn_rate\": 1},\n",
    "        {\"duration\": 120, \"users\": 4, \"spawn_rate\": 1},\n",
    "        {\"duration\": 150, \"users\": 5, \"spawn_rate\": 1},\n",
    "        {\"duration\": 180, \"users\": 4, \"spawn_rate\": 1},\n",
    "        {\"duration\": 210, \"users\": 3, \"spawn_rate\": 1},\n",
    "        {\"duration\": 240, \"users\": 2, \"spawn_rate\": 1},\n",
    "        {\"duration\": 270, \"users\": 1, \"spawn_rate\": 1}\n",
    "    ]\n",
    "\n",
    "    def tick(self):\n",
    "        run_time = self.get_run_time()\n",
    "\n",
    "        for stage in self.stages:\n",
    "            if run_time < stage[\"duration\"]:\n",
    "                tick_data = (stage[\"users\"], stage[\"spawn_rate\"])\n",
    "                return tick_data\n",
    "        # returning None to stop the load test\n",
    "        return None\n",
    "```\n",
    "\n",
    "Ajoutons \n",
    "\n",
    "```python\n",
    "@events.test_stop.add_listener\n",
    "def on_test_stop(environment, **kwargs):\n",
    "    process_exit_code = 0\n",
    "\n",
    "    max_requests_per_second = max(\n",
    "        [requests_per_second for requests_per_second in environment.stats.total.num_reqs_per_sec.values()])\n",
    "\n",
    "    if environment.stats.total.fail_ratio > 0.0:\n",
    "        logger.error(\"Test failed because there was one or more errors.\")\n",
    "        process_exit_code = 1\n",
    "\n",
    "    if environment.stats.total.get_response_time_percentile(0.99) > 100:\n",
    "        logger.error(\"Test failed because the response time at the 99th percentile was above 100 ms. The 99th \"\n",
    "                     \"percentile latency is '{}'.\".format(environment.stats.total.get_response_time_percentile(0.99)))\n",
    "        process_exit_code = 1\n",
    "\n",
    "    if max_requests_per_second < 5:\n",
    "        logger.error(\n",
    "            \"Test failed because the max requests per second never reached 5. The max requests per second \"\n",
    "            \"is: '{}'.\".format(max_requests_per_second))\n",
    "        process_exit_code = 1\n",
    "\n",
    "    environment.process_exit_code = process_exit_code\n",
    "```\n",
    "\n",
    "\n",
    "Nous ajoutons aussi la vérification des SLO suivants :\n",
    "\n",
    "Latence : nous vérifierons que la latence au 99e centile est inférieure à 100 ms.\n",
    "\n",
    "Taux d'erreur : nous vérifierons qu'il n'y a aucune erreur renvoyée pour toute demande.\n",
    "\n",
    "Débit : nous vérifierons que le service peut gérer au moins 5 requêtes par seconde.\n",
    "\n",
    "Avec une fonction listener qui reçoit des événements du package locust, nous pouvons vérifier les SLOs à la fin du test de charge. Si l'un des SLOs n'est pas respecté, nous définissons le code de sortie du processus sur 1, ce qui signale une défaillance.\n",
    "\n",
    "```python\n",
    "@events.test_stop.add_listener\n",
    "def on_test_stop(environment, **kwargs):\n",
    "    process_exit_code = 0\n",
    "\n",
    "    max_requests_per_second = max(\n",
    "        [requests_per_second for requests_per_second in environment.stats.total.num_reqs_per_sec.values()])\n",
    "\n",
    "    if environment.stats.total.fail_ratio > 0.0:\n",
    "        logger.error(\"Test failed because there was one or more errors.\")\n",
    "        process_exit_code = 1\n",
    "\n",
    "    if environment.stats.total.get_response_time_percentile(0.99) > 100:\n",
    "        logger.error(\"Test failed because the response time at the 99th percentile was above 100 ms. The 99th \"\n",
    "                     \"percentile latency is '{}'.\".format(environment.stats.total.get_response_time_percentile(0.99)))\n",
    "        process_exit_code = 1\n",
    "\n",
    "    if max_requests_per_second < 5:\n",
    "        logger.error(\n",
    "            \"Test failed because the max requests per second never reached 5. The max requests per second \"\n",
    "            \"is: '{}'.\".format(max_requests_per_second))\n",
    "        process_exit_code = 1\n",
    "\n",
    "    environment.process_exit_code = process_exit_code\n",
    "```\n",
    "\n",
    "\n",
    "Lançons le service de test Locust avec le fichier python :\n",
    "\n",
    "```bash\n",
    "pwd\n",
    "locust -f tests/load_test.py\n",
    "```\n",
    "\n",
    "Le Web App de Locust est accessible ici : http://127.0.0.1:8089.\n",
    "Nous allons lancer le test manuellement : \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dbf5d9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![External image](https://github.com/uqam-lomagnin/specifications-de-l-evolution-de-l-application-ml-ia_mgl7320_g1/blob/felix_load_tests/images/locust_making_requests_to_service.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad156507756ac423"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![External image](https://github.com/uqam-lomagnin/specifications-de-l-evolution-de-l-application-ml-ia_mgl7320_g1/blob/felix_load_tests/images/service_receiving_requests_from_locust.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f86ced772609c194"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![External image](https://github.com/uqam-lomagnin/specifications-de-l-evolution-de-l-application-ml-ia_mgl7320_g1/blob/felix_load_tests/images/locust_graphs_multiple_users.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55f3918dc52d35a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![External image](https://github.com/uqam-lomagnin/specifications-de-l-evolution-de-l-application-ml-ia_mgl7320_g1/blob/felix_load_tests/images/755_requests_made.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d85388c25d95e393"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![External image](https://github.com/uqam-lomagnin/specifications-de-l-evolution-de-l-application-ml-ia_mgl7320_g1/blob/felix_load_tests/images/docker_image_receiving_requests.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "628ce3d84f3a3366"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/felixzhao/Desktop/my-logging/logging-for-ml-models'"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%pwdpwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T23:17:09.430104Z",
     "start_time": "2023-12-14T23:17:09.412526Z"
    }
   },
   "id": "c0bff3f92c5621e7"
  },
  {
   "cell_type": "markdown",
   "id": "30d4c1fd",
   "metadata": {},
   "source": [
    "## Faisons un test de charge avec Locust mais sans UI\n",
    "\n",
    "La même commande de lancer le test mais sans UI pour automatiser le processus : \n",
    "\n",
    "```bash\n",
    "locust -f tests/load_test.py --host=http://127.0.0.1:8000 --headless --loglevel ERROR --csv=./load_test_report/load_test --html ./load_test_report/load_test_report.html\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Une fois réussi, nous pouvons voir le rapport de test de charge dans le dossier load_test_report :\n",
    "Et nous pouvons faire une autre image Docker avec Dockerfile-locust pour lancer le test de charge automatiquement :"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc5bd3eaf2abc129"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/felixzhao/Desktop/my-logging/logging-for-ml-models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixzhao/venv/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd Desktop/my-logging/logging-for-ml-models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T22:29:04.565496Z",
     "start_time": "2023-12-14T22:29:04.540786Z"
    }
   },
   "id": "b9c3c67b978a34f5"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1A\u001B[1B\u001B[0G\u001B[?25l[+] Building 0.0s (0/0)                                    docker:desktop-linux\r\n",
      "\u001B[?25h\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.0s (0/0)                                    docker:desktop-linux\r\n",
      "\u001B[?25h\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.0s (0/1)                                    docker:desktop-linux\r\n",
      "\u001B[?25h\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.2s (2/3)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 299B                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load build definition from Dockerfile-locust                0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 796B                                       0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/tiangolo/uvicorn-gunicorn-fast  0.1s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.3s (2/3)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 299B                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load build definition from Dockerfile-locust                0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 796B                                       0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/tiangolo/uvicorn-gunicorn-fast  0.3s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.5s (2/3)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 299B                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load build definition from Dockerfile-locust                0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 796B                                       0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/tiangolo/uvicorn-gunicorn-fast  0.4s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.6s (3/3)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 299B                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load build definition from Dockerfile-locust                0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 796B                                       0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/tiangolo/uvicorn-gunicorn-fast  0.5s\r\n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.7s (14/14) FINISHED                         docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 299B                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load build definition from Dockerfile-locust                0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 796B                                       0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/tiangolo/uvicorn-gunicorn-fast  0.5s\r\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 2.27kB                                        0.0s\r\n",
      "\u001B[0m\u001B[34m => [1/9] FROM docker.io/tiangolo/uvicorn-gunicorn-fastapi:python3.9@sha2  0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [2/9] WORKDIR /locust                                           0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [3/9] RUN apt-get update && apt-get upgrade -y                  0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [4/9] RUN apt-get update && apt-get install -y cron             0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [5/9] RUN pip install locust                                    0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [6/9] RUN pip install faker                                     0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [7/9] COPY ./tests/load_test.py ./tests/load_test.py            0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [8/9] COPY ./insurance_charges_model ./insurance_charges_model  0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [9/9] RUN ls -l /locust/tests/load_test.py                      0.0s\r\n",
      "\u001B[0m\u001B[34m => exporting to image                                                     0.0s\r\n",
      "\u001B[0m\u001B[34m => => exporting layers                                                    0.0s\r\n",
      "\u001B[0m\u001B[34m => => writing image sha256:7b0c45ebd580ca50539e1c12ac9a3057903c721d81768  0.0s\r\n",
      "\u001B[0m\u001B[34m => => naming to docker.io/library/my_locust4                              0.0s\r\n",
      "\u001B[0m\u001B[?25h\u001B[1m\r\n",
      "What's Next?\r\n",
      "\u001B[0m  1. Sign in to your Docker account → \u001B[36mdocker login\u001B[0m\r\n",
      "  2. View a summary of image vulnerabilities and recommendations → \u001B[36mdocker scout quickview\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!docker build -t my_locust4 -f Dockerfile-locust ."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T23:19:52.819473Z",
     "start_time": "2023-12-14T23:19:50.718097Z"
    }
   },
   "id": "93e5b1b36ba1cf32"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_locust4                                              latest            7b0c45ebd580   45 minutes ago   1.24GB\r\n"
     ]
    }
   ],
   "source": [
    "!docker image ls | grep my_locust4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T23:19:58.258847Z",
     "start_time": "2023-12-14T23:19:57.569320Z"
    }
   },
   "id": "419ab9ab9d073825"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                         0     0(0.00%) |      0       0       0      0 |    0.00        0.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                     2   2(100.00%) |     34      18      49     19 |    0.00        0.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                         2   2(100.00%) |     34      18      49     19 |    0.00        0.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                     4   4(100.00%) |     28       8      49     19 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                         4   4(100.00%) |     28       8      49     19 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                     6   6(100.00%) |     21       5      49      9 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                         6   6(100.00%) |     21       5      49      9 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                     9   9(100.00%) |     17       5      49      9 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                         9   9(100.00%) |     17       5      49      9 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    10  10(100.00%) |     16       5      49      9 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        10  10(100.00%) |     16       5      49      9 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    12  12(100.00%) |     15       5      49      9 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        12  12(100.00%) |     15       5      49      9 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    14  14(100.00%) |     21       5      75     10 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        14  14(100.00%) |     21       5      75     10 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    17  17(100.00%) |     21       5      75     10 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        17  17(100.00%) |     21       5      75     10 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    19  19(100.00%) |     20       5      75     10 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        19  19(100.00%) |     20       5      75     10 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    21  21(100.00%) |     20       5      75     10 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        21  21(100.00%) |     20       5      75     10 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    23  23(100.00%) |     19       5      75     10 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        23  23(100.00%) |     19       5      75     10 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    25  25(100.00%) |     19       5      75     10 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        25  25(100.00%) |     19       5      75     10 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    27  27(100.00%) |     18       5      75     10 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        27  27(100.00%) |     18       5      75     10 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    28  28(100.00%) |     18       5      75     10 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        28  28(100.00%) |     18       5      75     10 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    31  31(100.00%) |     17       4      75      9 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        31  31(100.00%) |     17       4      75      9 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    35  35(100.00%) |     16       4      75      9 |    1.00        1.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        35  35(100.00%) |     16       4      75      9 |    1.00        1.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    39  39(100.00%) |     15       4      75      8 |    1.20        1.20\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        39  39(100.00%) |     15       4      75      8 |    1.20        1.20\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    43  43(100.00%) |     14       4      75      8 |    1.40        1.40\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        43  43(100.00%) |     14       4      75      8 |    1.40        1.40\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    47  47(100.00%) |     14       3      75      8 |    1.60        1.60\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        47  47(100.00%) |     14       3      75      8 |    1.60        1.60\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    51  51(100.00%) |     13       3      75      8 |    1.80        1.80\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        51  51(100.00%) |     13       3      75      8 |    1.80        1.80\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    55  55(100.00%) |     13       3      75      8 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        55  55(100.00%) |     13       3      75      8 |    2.00        2.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    59  59(100.00%) |     12       3      75      7 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        59  59(100.00%) |     12       3      75      7 |    2.00        2.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    63  63(100.00%) |     12       3      75      7 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        63  63(100.00%) |     12       3      75      7 |    2.00        2.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    67  67(100.00%) |     11       2      75      7 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        67  67(100.00%) |     11       2      75      7 |    2.00        2.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    71  71(100.00%) |     11       2      75      7 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        71  71(100.00%) |     11       2      75      7 |    2.00        2.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    75  75(100.00%) |     11       2      75      7 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        75  75(100.00%) |     11       2      75      7 |    2.00        2.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    79  79(100.00%) |     10       2      75      6 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        79  79(100.00%) |     10       2      75      6 |    2.00        2.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    83  83(100.00%) |     10       2      75      7 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        83  83(100.00%) |     10       2      75      7 |    2.00        2.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    86  86(100.00%) |     11       2      75      7 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        86  86(100.00%) |     11       2      75      7 |    2.00        2.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    92  92(100.00%) |     17       2     406      7 |    1.90        1.90\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        92  92(100.00%) |     17       2     406      7 |    1.90        1.90\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                    98  98(100.00%) |     25       2     406      7 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                        98  98(100.00%) |     25       2     406      7 |    2.00        2.00\r\n",
      "\r\n",
      "Type     Name                                                                          # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "POST     /api/models/insurance_charges_model/prediction                                   101 101(100.00%) |     28       2     406      7 |    2.00        2.00\r\n",
      "--------|----------------------------------------------------------------------------|-------|-------------|-------|-------|-------|-------|--------|-----------\r\n",
      "         Aggregated                                                                       101 101(100.00%) |     28       2     406      7 |    2.00        2.00\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 8089:8089 my_locust4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T23:21:16.662920Z",
     "start_time": "2023-12-14T23:20:04.123161Z"
    }
   },
   "id": "4bd94db5e849c614"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Références\n",
    "\n",
    "https://github.com/schmidtbri/load-tests-for-ml-models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3a34b0d9749ce90"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
